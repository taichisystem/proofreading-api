{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1104f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "import torch\n",
    "from transformers import BertJapaneseTokenizer, BertForMaskedLM\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5eb302",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SC_tokenizer(BertJapaneseTokenizer):\n",
    "    def encode_plus_tagged(\n",
    "        self, wrong_text, correct_text, max_length=128\n",
    "    ):\n",
    "        \"\"\"\n",
    "        ファインチューニング時に使用。\n",
    "        誤変換を含む文章と正しい文章を入力とし、\n",
    "        符号化を行いBERTに入力できる形式にする。\n",
    "        \"\"\"\n",
    "        # 誤変換した文章をトークン化し、符号化\n",
    "        encoding = self(\n",
    "            wrong_text, \n",
    "            max_length=max_length, \n",
    "            padding='max_length', \n",
    "            truncation=True\n",
    "        )\n",
    "        # 正しい文章をトークン化し、符号化\n",
    "        encoding_correct = self(\n",
    "            correct_text,\n",
    "            max_length=max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        ) \n",
    "        # 正しい文章の符号をラベルとする\n",
    "        encoding['labels'] = encoding_correct['input_ids'] \n",
    "\n",
    "        return encoding\n",
    "    def encode_plus_untagged(\n",
    "        self, text, max_length=None, return_tensors=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        文章を符号化し、それぞれのトークンの文章中の位置も特定しておく。\n",
    "        \"\"\"\n",
    "        # 文章のトークン化を行い、\n",
    "        # それぞれのトークンと文章中の文字列を対応づける。\n",
    "        tokens = [] # トークンを追加していく。\n",
    "        tokens_original = [] # トークンに対応する文章中の文字列を追加していく。\n",
    "        words = self.word_tokenizer.tokenize(text) # MeCabで単語に分割\n",
    "        for word in words:\n",
    "            # 単語をサブワードに分割\n",
    "            tokens_word = self.subword_tokenizer.tokenize(word) \n",
    "            tokens.extend(tokens_word)\n",
    "            if tokens_word[0] == '[UNK]': # 未知語への対応\n",
    "                tokens_original.append(word)\n",
    "            else:\n",
    "                tokens_original.extend([\n",
    "                    token.replace('##','') for token in tokens_word\n",
    "                ])\n",
    "\n",
    "        # 各トークンの文章中での位置を調べる。（空白の位置を考慮する）\n",
    "        position = 0\n",
    "        spans = [] # トークンの位置を追加していく。\n",
    "        for token in tokens_original:\n",
    "            l = len(token)\n",
    "            while 1:\n",
    "                if token != text[position:position+l]:\n",
    "                    position += 1\n",
    "                else:\n",
    "                    spans.append([position, position+l])\n",
    "                    position += l\n",
    "                    break\n",
    "\n",
    "        # 符号化を行いBERTに入力できる形式にする。\n",
    "        input_ids = self.convert_tokens_to_ids(tokens) \n",
    "        encoding = self.prepare_for_model(\n",
    "            input_ids, \n",
    "            max_length=max_length, \n",
    "            padding='max_length' if max_length else False, \n",
    "            truncation=True if max_length else False\n",
    "        )\n",
    "        sequence_length = len(encoding['input_ids'])\n",
    "        # 特殊トークン[CLS]に対するダミーのspanを追加。\n",
    "        spans = [[-1, -1]] + spans[:sequence_length-2] \n",
    "        # 特殊トークン[SEP]、[PAD]に対するダミーのspanを追加。\n",
    "        spans = spans + [[-1, -1]] * ( sequence_length - len(spans) ) \n",
    "        \n",
    "        # 必要に応じてtorch.Tensorにする。\n",
    "        if return_tensors == 'pt':\n",
    "            encoding = { k: torch.tensor([v]) for k, v in encoding.items() }\n",
    "\n",
    "        return encoding, spans\n",
    "    def convert_bert_output_to_text(self, text, labels, spans):\n",
    "        \"\"\"\n",
    "        推論時に使用。\n",
    "        文章と、各トークンのラベルの予測値、文章中での位置を入力とする。\n",
    "        そこから、BERTによって予測された文章に変換。\n",
    "        \"\"\"\n",
    "        assert len(spans) == len(labels)\n",
    "\n",
    "        # labels, spansから特殊トークンに対応する部分を取り除く\n",
    "        labels = [label for label, span in zip(labels, spans) if span[0]!=-1]\n",
    "        spans = [span for span in spans if span[0]!=-1]\n",
    "\n",
    "        # BERTが予測した文章を作成\n",
    "        predicted_text = ''\n",
    "        position = 0\n",
    "        for label, span in zip(labels, spans):\n",
    "            start, end = span\n",
    "            if position != start: # 空白の処理\n",
    "                predicted_text += text[position:start]\n",
    "            predicted_token = self.convert_ids_to_tokens(label)\n",
    "            predicted_token = predicted_token.replace('##', '')\n",
    "            predicted_token = unicodedata.normalize(\n",
    "                'NFKC', predicted_token\n",
    "            ) \n",
    "            predicted_text += predicted_token\n",
    "            position = end\n",
    "        \n",
    "        return predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd727b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMaskedLM_pl(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, model_name, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.bert_mlm = BertForMaskedLM.from_pretrained(model_name)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        output = self.bert_mlm(**batch)\n",
    "        loss = output.loss\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        output = self.bert_mlm(**batch)\n",
    "        val_loss = output.loss\n",
    "        self.log('val_loss', val_loss)\n",
    "   \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0891605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(model_dir):\n",
    "    tokenizer = SC_tokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
    "    model = BertForMaskedLM_pl.load_from_checkpoint(os.path.join(model_dir, '<モデル(ckpt 形式) のファイル名>'))\n",
    "    bert_mlm = model.bert_mlm.cuda()\n",
    "    return bert_mlm, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d01a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(data, model_and_tokenizer):\n",
    "    bert_mlm, tokenizer = model_and_tokenizer\n",
    "    text = data['inputs']\n",
    "\n",
    "    encoding, spans = tokenizer.encode_plus_untagged(\n",
    "        text, return_tensors='pt'\n",
    "    )\n",
    "    encoding = { k: v.cuda() for k, v in encoding.items() }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = bert_mlm(**encoding)\n",
    "        scores = output.logits\n",
    "        labels_predicted = scores[0].argmax(-1).cpu().numpy().tolist()\n",
    "\n",
    "    predict_text = tokenizer.convert_bert_output_to_text(\n",
    "        text, labels_predicted, spans\n",
    "    )\n",
    "\n",
    "    return predict_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
